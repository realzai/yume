# TODO setup tokenizer
class Tokenizer:
    def __init__(self):
        pass

    def train(self):
        pass

    def encode(self, texts):
        result = ""
        return []

    def decode(self, tensors):
        result = ""
        return tensors

    def load_pretrained(self):
        pass
